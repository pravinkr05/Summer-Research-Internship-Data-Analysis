{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#@title #####**Connect with drive**\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"Jq7s6MuIKbZ_","executionInfo":{"status":"error","timestamp":1701797833603,"user_tz":-330,"elapsed":13677,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}},"outputId":"184efbe2-3ef9-4e76-9d7d-dc91ee69e9d0","cellView":"form"},"execution_count":1,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f825741fe815>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title #####**Connect with drive**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s611La5gqEWJ","cellView":"form","executionInfo":{"status":"aborted","timestamp":1701797833606,"user_tz":-330,"elapsed":46,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"outputs":[],"source":["#@title #####**Storing the sequence in their category**\n","import os\n","\n","# Define the paths to the folders containing the text files\n","folder_paths = ['/content/drive/MyDrive/Summer Internship Aliah University/GENE_EXPRESSIONS_DATA/AT', '/content/drive/MyDrive/Summer Internship Aliah University/GENE_EXPRESSIONS_DATA/DOM', '/content/drive/MyDrive/Summer Internship Aliah University/GENE_EXPRESSIONS_DATA/DR']  # Replace with actual folder paths\n","\n","# Initialize empty arrays for each class\n","class1_sequences = []\n","class2_sequences = []\n","class3_sequences = []\n","\n","# Iterate over each folder\n","for i, folder_path in enumerate(folder_paths):\n","    # Get the list of files in the folder\n","\n","    file_list = os.listdir(folder_path)\n","\n","    # Iterate over each file in the folder\n","    for file_name in file_list:\n","        file_path = os.path.join(folder_path, file_name)\n","        # print(file_path)\n","        # file_path='AT/3.txt'\n","        # Open the file and read the gene sequence\n","        with open(file_path, 'r') as file:\n","            sequence = file.read().strip()  # Assuming each file contains a single sequence per line\n","\n","        # Add the sequence to the appropriate class array based on the folder index\n","        if i == 0:\n","            class1_sequences.append(sequence)\n","        elif i == 1:\n","            class2_sequences.append(sequence)\n","        elif i == 2:\n","            class3_sequences.append(sequence)\n","\n","# Print the sequences for verification\n","print(\"Class 1 Sequences:\")\n","for i,sequence in enumerate(class1_sequences):\n","    print(sequence,\"\\n \")\n","    if(i==5):\n","      break;\n","print()\n","\n","print(\"Class 2 Sequences:\")\n","for i,sequence in enumerate(class2_sequences):\n","    print(sequence,\"\\n \")\n","    if(i==5):\n","      break;\n","print()\n","\n","print(\"Class 3 Sequences:\")\n","for i,sequence in enumerate(class3_sequences):\n","    print(sequence,\"\\n \")\n","    if(i==5):\n","      break;\n"]},{"cell_type":"markdown","source":["**==========================================Task number - 1===========================================**"],"metadata":{"id":"gFMjnTpg3ryx"}},{"cell_type":"markdown","source":["**1. Shanon Entropy**: Measure the degree of uncertainty or randomness in the sequence.\n","\n","---\n","\n","The *compute_shannon_entropy* function takes a gene sequence as input, calculates the relative frequencies of each unique element (nucleotide), and then computes the Shannon entropy using the entropy function from the scipy.stats module.\n","\n","\n","\n","\n","\n","\n","\n","---\n","\n","\n","\n","\n"],"metadata":{"id":"Xsz2Xaa4XV6h"}},{"cell_type":"code","source":["#@title #####**Compute shanon entropy**\n","# !pip install scipy\n","\n","\n","import numpy as np\n","from scipy.stats import entropy\n","# from sklearn.feature_selection import SelectKBest, chi2\n","from sklearn.feature_selection import SelectKBest, f_classif\n","\n","# Define the feature extraction functions\n","\n","def compute_shannon_entropy(sequence):\n","    unique_elements, counts = np.unique(list(sequence), return_counts=True)\n","    probabilities = counts / len(sequence)\n","    entropy_value = entropy(probabilities, base=2)\n","    return entropy_value\n","\n","# Compute features for each sequence in each class\n","\n","category1_features = []\n","for sequence in class1_sequences:\n","    entropy_value = compute_shannon_entropy(sequence)\n","    category1_features.append([entropy_value])\n","\n","\n","category2_features = []\n","for sequence in class2_sequences:\n","    entropy_value = compute_shannon_entropy(sequence)\n","    category2_features.append([entropy_value])\n","    # print(sequence)\n","    # print(entropy_value)\n","\n","category3_features = []\n","for sequence in class3_sequences:\n","    entropy_value = compute_shannon_entropy(sequence)\n","    category3_features.append([entropy_value])\n","    # print(sequence)\n","    # print(entropy_value)\n","\n","# Combine the features and labels for classification\n","all_features = category1_features + category2_features + category3_features\n","labels = [0] * len(class1_sequences) + [1] * len(class2_sequences) + [2] * len(class3_sequences)\n","\n","print(\"total no. of features \",len(all_features))\n","print(\"total no. of labels \",len(labels))\n","\n","print(\"five features \",all_features[:5])\n","print(\"five labels \",labels[:5])\n","\n","\n","# Perform feature selection using ANOVA F-test\n","selector = SelectKBest(score_func=f_classif, k='all')\n","selected_features = selector.fit_transform(all_features, labels)\n","shanon_entropy_features = all_features\n","# print(\"Selected Features:\")\n","# print(selected_features)\n","# print(len(selected_features))\n","# print([1]*len(class2_sequences)\n","\n"],"metadata":{"id":"pbS4uc2qAghO","executionInfo":{"status":"aborted","timestamp":1701797833609,"user_tz":-330,"elapsed":49,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}},"cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Split the data into training and testing sets**\n","print('0: ',labels.count(0),'\\n1: ',labels.count(1),'\\n2: ',labels.count(2))\n","\n","# 50%=(178,170,158)--36%, 60%(214,204,189)--37%,70%(250,238,221)--39%,80%(285,271,252)--36%\n","n1=214\n","n2=204+356\n","n3=189+695\n","# n1=250\n","# n2=238+356\n","# n3=221+695\n","# n1=285\n","# n2=271+356\n","# n3=252+695\n","train_0_x=selected_features[:n1]\n","test_0_x=selected_features[n1:356]\n","train_1_x=selected_features[356:n2]\n","test_1_x=selected_features[n2:695]\n","train_2_x=selected_features[695:n3]\n","test_2_x=selected_features[n3:]\n","\n","train_0_y=labels[:n1]\n","test_0_y=labels[n1:356]\n","train_1_y=labels[356:n2]\n","test_1_y=labels[n2:695]\n","train_2_y=labels[695:n3]\n","test_2_y=labels[n3:]\n","# train_0_x.dtypes\n","# print(train_0_x)\n","X_train=np.concatenate((train_0_x,train_1_x,train_2_x),axis=0)\n","X_test = np.concatenate((test_0_x,test_1_x,test_2_x),axis=0)\n","y_train=np.concatenate((train_0_y,train_1_y,train_2_y),axis=0)\n","y_test = np.concatenate((test_0_y,test_1_y,test_2_y),axis=0)\n","\n","\n","# y_test"],"metadata":{"id":"EC3Vhv3LMtTr","executionInfo":{"status":"aborted","timestamp":1701797833610,"user_tz":-330,"elapsed":49,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}},"cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Testing and Training The Model**\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Train a decision tree classifier (a classification model using the features and labels)\n","clf = DecisionTreeClassifier()\n","clf.fit(X_train, y_train)\n","\n","# Predict labels for test data\n","y_pred = clf.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n","# Classify new gene sequences\n","new_sequences =[\"ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG\" ,\"GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTA\", \"AGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAG\"]\n","\n","new_features = []\n","for sequence in new_sequences:\n","    entropy_value = compute_shannon_entropy(sequence)\n","    new_features.append([entropy_value])\n","\n","predicted_categories = clf.predict(new_features)\n","print(\"Predicted Categories:\", predicted_categories)\n"],"metadata":{"id":"nOdyWAE7J-Qb","executionInfo":{"status":"aborted","timestamp":1701797833611,"user_tz":-330,"elapsed":50,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}},"cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**2. Hurst exponent**: Capture long-term memory or self-similarity properties.\n","\n","\n","---\n","\n","\n","The *compute_hurst_exponent* function takes a gene sequence as input, converts it into a numeric sequence, and computes the Hurst exponent using the compute_Hc function from the hurst module.\n","  \\\n","The Hurst exponent is typically calculated for time series data with a sufficient number of data points, and the error you encountered suggests that the length of your gene sequences may be too short to calculate the Hurst exponent reliably. The Hurst exponent is commonly used in analyzing long-range dependence and self-similarity in time series data.\n"],"metadata":{"id":"uTIbvlN8dPKf"}},{"cell_type":"code","source":["#@title #####**Compute Hurst Exponent**\n","!pip install hurst\n","!pip install scikit-learn\n","print(\"===========================================================================================================================\\n\")\n","import numpy as np\n","from hurst import compute_Hc\n","from sklearn.feature_selection import SelectKBest, f_classif\n","\n","# Define the feature extraction functions\n","\n","def compute_hurst_exponent(sequence):\n","    numeric_sequence = np.array([ord(nucleotide) - ord('A') for nucleotide in sequence])\n","    hurst_exponent, _, _ = compute_Hc(numeric_sequence)\n","    return hurst_exponent\n","\n","# Compute features for each sequence in each category\n","\n","category1_features = []\n","for sequence in class1_sequences:\n","    hurst_exponent = compute_hurst_exponent(sequence)\n","    # print(hurst_exponent)\n","    category1_features.append([hurst_exponent])\n","\n","category2_features = []\n","for sequence in class2_sequences:\n","    hurst_exponent = compute_hurst_exponent(sequence)\n","    category2_features.append([hurst_exponent])\n","\n","category3_features = []\n","for sequence in class3_sequences:\n","    hurst_exponent = compute_hurst_exponent(sequence)\n","    category3_features.append([hurst_exponent])\n","\n","# Combine the features and labels for classification\n","\n","all_features = category1_features + category2_features + category3_features\n","labels = [0] * len(class1_sequences) + [1] * len(class2_sequences) + [2] * len(class3_sequences)\n","\n","print(\"total no. of features \",len(all_features))\n","print(\"total no. of labels \",len(labels))\n","\n","print(\"five features \",all_features[:5])\n","print(\"five labels \",labels[:5])\n","\n","# Perform feature selection using ANOVA F-test\n","selector = SelectKBest(score_func=f_classif, k='all')\n","selected_features = selector.fit_transform(all_features, labels)\n","hurst_exponent_features = all_features\n","# print(\"Selected Features:\")\n","# print(selected_features[:5])\n","\n","# print(\"length\" ,len(selected_features))\n"],"metadata":{"id":"mnUFT_nfJcor","executionInfo":{"status":"aborted","timestamp":1701797833611,"user_tz":-330,"elapsed":50,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Split the data into training and testing sets**\n","print('0: ',labels.count(0),'\\n1: ',labels.count(1),'\\n2: ',labels.count(2))\n","\n","# 50%=(178,170,158)--42.8%, 60%(214,204,189)--43%,70%(250,238,221)--43%,80%(285,271,252)--45%\n","n1=178\n","n2=170+356\n","n3=158+695\n","# n1=214\n","# n2=204+356\n","# n3=189+695\n","# n1=250\n","# n2=238+356\n","# n3=221+695\n","# n1=285\n","# n2=271+356\n","# n3=252+695\n","train_0_x=selected_features[:n1]\n","test_0_x=selected_features[n1:356]\n","train_1_x=selected_features[356:n2]\n","test_1_x=selected_features[n2:695]\n","train_2_x=selected_features[695:n3]\n","test_2_x=selected_features[n3:]\n","\n","train_0_y=labels[:n1]\n","test_0_y=labels[n1:356]\n","train_1_y=labels[356:n2]\n","test_1_y=labels[n2:695]\n","train_2_y=labels[695:n3]\n","test_2_y=labels[n3:]\n","\n","# print(train_0_x)\n","\n","X_train=np.concatenate((train_0_x,train_1_x,train_2_x),axis=0)\n","X_test = np.concatenate((test_0_x,test_1_x,test_2_x),axis=0)\n","y_train=np.concatenate((train_0_y,train_1_y,train_2_y),axis=0)\n","y_test = np.concatenate((test_0_y,test_1_y,test_2_y),axis=0)\n"],"metadata":{"id":"uRsScH8OaXmp","executionInfo":{"status":"aborted","timestamp":1701797833617,"user_tz":-330,"elapsed":49,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}},"cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Testing and Training The Model**\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Train a decision tree classifier\n","clf = DecisionTreeClassifier()\n","clf.fit(X_train, y_train)\n","\n","# Predict labels for test data\n","y_pred = clf.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n","# Classify new gene sequences length 100\n","new_sequences =[\"ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG\" ,\"GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTA\", \"AGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAG\"]\n","new_features = []\n","for sequence in new_sequences:\n","    # print(len(sequence))\n","    hurst_exponent = compute_hurst_exponent(sequence)\n","    new_features.append([hurst_exponent])\n","\n","predicted_categories = clf.predict(new_features)\n","print(\"Predicted Categories:\", predicted_categories)\n"],"metadata":{"id":"AskGEGASIxMY","executionInfo":{"status":"aborted","timestamp":1701797833617,"user_tz":-330,"elapsed":48,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}},"cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rgCnZDwZ32Ya","executionInfo":{"status":"aborted","timestamp":1701797833618,"user_tz":-330,"elapsed":49,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PHi48A8r32EV","executionInfo":{"status":"aborted","timestamp":1701797833619,"user_tz":-330,"elapsed":49,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gMw5m9xS310u","executionInfo":{"status":"aborted","timestamp":1701797833621,"user_tz":-330,"elapsed":50,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**==========================================Task number - 2===========================================**"],"metadata":{"id":"VkPDAhrY3hrs"}},{"cell_type":"markdown","source":["**3. Run-length encoding** (RLE) is a simple compression technique that can also be used as a feature extraction method. It involves representing consecutive repeated elements in a sequence with a count of the element and the element itself."],"metadata":{"id":"es9P1NPl-No4"}},{"cell_type":"code","source":["#@title #####**Run Length Encoding**\n","\n","import numpy as np\n","from sklearn.feature_selection import SelectKBest, f_classif\n","\n","# Define the feature extraction functions\n","\n","def compute_rle_features(sequence):\n","    encoded_sequence = []\n","    count = 1\n","    for i in range(1, len(sequence)):\n","        if sequence[i] == sequence[i-1]:\n","            count += 1\n","        else:\n","            encoded_sequence.append((count, sequence[i-1]))\n","            count = 1\n","    encoded_sequence.append((count, sequence[-1]))\n","\n","    return encoded_sequence\n","\n","# Compute features for each sequence in each category\n","\n","category1_features = []\n","for sequence in class1_sequences:\n","    rle_features = compute_rle_features(sequence)\n","    category1_features.append(rle_features)\n","\n","# # Convert RLE features into numerical format\n","numeric_features = []\n","for sequence_rle_features in category1_features:\n","    numeric_features.append([count for count, _ in sequence_rle_features])\n","\n","numeric_features1 = np.array((numeric_features),dtype=object)\n","\n","category2_features = []\n","for sequence in class2_sequences:\n","    rle_features = compute_rle_features(sequence)\n","    category2_features.append(rle_features)\n","\n","# Convert RLE features into numerical format\n","numeric_features = []\n","for sequence_rle_features in category2_features:\n","    numeric_features.append([count for count, _ in sequence_rle_features])\n","\n","numeric_features2 = np.array((numeric_features),dtype=object)\n","\n","category3_features = []\n","for sequence in class3_sequences:\n","    rle_features = compute_rle_features(sequence)\n","    category3_features.append(rle_features)\n","\n","# Convert RLE features into numerical format\n","numeric_features = []\n","for sequence_rle_features in category3_features:\n","    numeric_features.append([count for count, _ in sequence_rle_features])\n","\n","numeric_features3 = np.array((numeric_features),dtype=object)\n","\n","# Combine the features and labels for classification\n","\n","selected_features = np.concatenate((numeric_features1 ,numeric_features2, numeric_features3),axis=0)\n","labels = [0] * len(class1_sequences) + [1] * len(class2_sequences) + [2] * len(class3_sequences)\n","\n","\n","selected_features =  np.array((selected_features), dtype=object)\n","\n","\n","print(\"length of features \",len(selected_features))\n","print(\"length of labels \",len(labels))\n","\n","# print(selected_features[:5])\n","# print(labels[:5])\n","\n","# # Perform feature selection using ANOVA F-test\n","# selector = SelectKBest(score_func=f_classif, k='all')\n","# selected_features = selector.fit_transform(selected_features, labels)\n","\n","print(\"Selected Features:\")\n","print(selected_features[:5])\n","print(\"labels \",labels[:5])\n","# print(len(selected_features))"],"metadata":{"id":"Uq1ysEnM9DSn","executionInfo":{"status":"aborted","timestamp":1701797833623,"user_tz":-330,"elapsed":51,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}},"cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Run Length Encoding Static Value**\n","# Compute statistic value of features for each RLE sequence\n","import pandas as  pd\n","import numpy as np\n","from scipy.stats import skew, kurtosis, entropy\n","\n","static_features = pd.DataFrame(columns=[\"Energy\",\"Skewness\",\"Kurtosis\",\"Entropy\",\"Correlation\",'Mean','Std'])\n","select_features = []\n","i=-1\n","for sequence in selected_features:\n","    length = len(sequence)\n","    mean = sum(sequence) / length\n","    std_dev = np.std(sequence)\n","    energy = np.sum(np.square(sequence))\n","    skewness = skew(sequence)\n","    kurt = kurtosis(sequence)\n","    ent = entropy(sequence)\n","    corr = np.correlate(sequence,sequence, mode='valid')[0]\n","    i=i+1\n","    # select_features.append([std_dev])\n","    static_features.loc[i] = [energy,skewness,kurt,ent,corr,mean,std_dev]\n","\n","print(static_features[:5])\n","print(len(static_features))\n","# static_features['Correlation']"],"metadata":{"id":"_x81goqO5EVE","executionInfo":{"status":"aborted","timestamp":1701797833623,"user_tz":-330,"elapsed":51,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}},"cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Apply Min-Max Normalization**\n","df1=static_features\n","df_norm = (df1-df1.min())/(df1.max()-df1.min())\n","static_features=df_norm\n","static_features.head()"],"metadata":{"id":"qCCP_1v-HYOK","executionInfo":{"status":"aborted","timestamp":1701797833624,"user_tz":-330,"elapsed":51,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}},"cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Split the data into training and testing sets**\n","print('0: ',labels.count(0),'\\n1: ',labels.count(1),'\\n2: ',labels.count(2))\n","selected_features = static_features\n","# 50%=(178,170,158)---48%\n","n1=178\n","n2=170+356\n","n3=158+695\n","\n","train_0_x=selected_features[:n1]\n","test_0_x=selected_features[n1:356]\n","train_1_x=selected_features[356:n2]\n","test_1_x=selected_features[n2:695]\n","train_2_x=selected_features[695:n3]\n","test_2_x=selected_features[n3:]\n","\n","train_0_y=labels[:n1]\n","test_0_y=labels[n1:356]\n","train_1_y=labels[356:n2]\n","test_1_y=labels[n2:695]\n","train_2_y=labels[695:n3]\n","test_2_y=labels[n3:]\n","\n","# print(train_0_x)\n","\n","X_train=np.concatenate((train_0_x,train_1_x,train_2_x),axis=0)\n","X_test = np.concatenate((test_0_x,test_1_x,test_2_x),axis=0)\n","y_train=np.concatenate((train_0_y,train_1_y,train_2_y),axis=0)\n","y_test = np.concatenate((test_0_y,test_1_y,test_2_y),axis=0)\n","print(X_train[:5])"],"metadata":{"id":"nPmqUShEZiE5","executionInfo":{"status":"aborted","timestamp":1701797833624,"user_tz":-330,"elapsed":50,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}},"cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**testing and training the model**\n","from sklearn.metrics._plot.regression import PredictionErrorDisplay\n","import pandas as  pd\n","import numpy as np\n","from scipy.stats import skew, kurtosis, entropy\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Train a decision tree classifier\n","clf = DecisionTreeClassifier()\n","clf.fit(X_train, y_train)\n","\n","# Predict labels for test data\n","y_pred = clf.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n","\n","# Classify new gene sequences length 100\n","new_sequences =[\"ACACACGCCGGGGTTCATCATGGCGGCGGGACCGATTTCAGAACGAAATCAAGATGCCGCTGTATATGTGG\" ,\"ATGACGACTCGAATCGCTCCTGGTGTTGGAGCTAATCTTCTCGGCCAACACTCCGCTGAGAGGAACCAAGACGCCACTGTTTACGT\",\"ATGTCTCGTCACGAGAAAACGAAATCCACGGGCGGCGGGCTCCTGGACAGTCTGTTCGGAAGACCCTCGAAGTCCAAGG\"]\n","new_features = []\n","for sequence in new_sequences:\n","    rle_features = compute_rle_features(sequence)\n","    new_features.append(rle_features)\n","\n","# Convert RLE features into numerical format\n","numeric_features = []\n","for sequence_rle_features in new_features:\n","    numeric_features.append([count for count, _ in sequence_rle_features])\n","\n","\n","# Convert RLE features into extended format\n","new_numeric_features = pd.DataFrame(columns=[\"Energy\",\"Skewness:\",\"Kurtosis\",\"Entropy\",\"Correlation\",'Mean','Std'])\n","i=-1\n","for sequence in numeric_features:\n","    print(sequence)\n","    length = len(sequence)\n","    mean = sum(sequence) / length\n","    std_dev = np.std(sequence)\n","    energy = np.sum(np.square(sequence))\n","    skewness = skew(sequence)\n","    kurt = kurtosis(sequence)\n","    ent = entropy(sequence)\n","    corr = np.correlate(sequence,sequence, mode='valid')[0]\n","    i=i+1\n","    new_numeric_features.loc[i] = [energy,skewness,kurt,ent,corr,mean,std_dev]\n","\n","df1=new_numeric_features\n","df_norm = (df1-df1.min())/(df1.max()-df1.min())\n","new_numeric_features=df_norm\n","\n","# new_numeric_features = np.array((new_numeric_features),dtype=object)\n","# print(new_numeric_features)\n","predicted_categories = clf.predict(new_numeric_features.values)\n","print(\"Predicted Categories:\", predicted_categories)\n"],"metadata":{"id":"c_7paN5H9vo4","executionInfo":{"status":"aborted","timestamp":1701797833625,"user_tz":-330,"elapsed":50,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}},"cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gDcfyGYc38Kk","executionInfo":{"status":"aborted","timestamp":1701797833626,"user_tz":-330,"elapsed":50,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1xcBTi8X37gY","executionInfo":{"status":"aborted","timestamp":1701797833627,"user_tz":-330,"elapsed":51,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3p8IJ6dQ37Y0","executionInfo":{"status":"aborted","timestamp":1701797833627,"user_tz":-330,"elapsed":50,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**==========================================Task number - 3===========================================**"],"metadata":{"id":"4yZkN95h3K2s"}},{"cell_type":"code","source":["# seq=[\"CAGGTT\",\"AAATTGGC\",\"AGTC\"]-->[[1,1,2,2],[3,2,2,1],[1,1,1,1]]\n","#@title #####**Concating two files**\n","all_features = shanon_entropy_features\n","all_features2 = hurst_exponent_features\n","print(\"shanon_entropy_features: \",all_features[:5])\n","print(\"hurst_exponent_features: \",all_features2[:5])"],"metadata":{"id":"RY5tltaIfQFl","executionInfo":{"status":"aborted","timestamp":1701797833628,"user_tz":-330,"elapsed":51,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}},"cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Export output.csv file**\n","import csv\n","\n","# Convert coulmns value string to float\n","all_features = [float(value) for sublist in all_features for value in sublist]\n","all_features2 = [float(value) for sublist in all_features2 for value in sublist]\n","# Combine the data into rows\n","rows = zip(all_features, all_features2, labels)\n","\n","# Specify the output CSV file path\n","output_file = \"output.csv\"\n","\n","# Write the data to the CSV file\n","with open(output_file, mode='w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"shanon_entropy\", \"hurst_exponent\", \"labels\"])  # Write the header row\n","    writer.writerows(rows)  # Write the data rows\n","\n","print(\"CSV file has been exported successfully.\")\n","\n","\n"],"metadata":{"cellView":"form","id":"D5dRxLvyySsD","executionInfo":{"status":"aborted","timestamp":1701797833628,"user_tz":-330,"elapsed":51,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Read output.csv file**\n","import pandas as pd\n","\n","df=pd.read_csv('output.csv')\n","# Convert all columns to floats\n","print(df.dtypes)\n","df.head()\n"],"metadata":{"cellView":"form","id":"QpjR5-eb038-","executionInfo":{"status":"aborted","timestamp":1701797833630,"user_tz":-330,"elapsed":52,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Apply Min-Max Normalization**\n","\n","df1 = df.drop('labels', axis=1)\n","df_norm = (df1-df1.min())/(df1.max()-df1.min())\n","df_norm = pd.concat((df_norm, df.labels),1)\n","df=df_norm\n","df.head()"],"metadata":{"cellView":"form","id":"XV7Y3y0N08rU","executionInfo":{"status":"aborted","timestamp":1701797833631,"user_tz":-330,"elapsed":53,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Select  features and labels**\n","selected_features=df.drop('labels',axis=1)\n","labels=df.labels\n","print(labels.head())\n","print(selected_features.head())"],"metadata":{"cellView":"form","id":"8G_QSV8g1AZ_","executionInfo":{"status":"aborted","timestamp":1701797833632,"user_tz":-330,"elapsed":54,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Split the data into training and testing sets**\n","\n","print(labels.value_counts())\n","\n","# 50%=(178,170,158)--36%\n","n1=214\n","n2=204+356\n","n3=189+695\n","\n","train_0_x=selected_features[:n1]\n","test_0_x=selected_features[n1:356]\n","train_1_x=selected_features[356:n2]\n","test_1_x=selected_features[n2:695]\n","train_2_x=selected_features[695:n3]\n","test_2_x=selected_features[n3:]\n","\n","train_0_y=labels[:n1]\n","test_0_y=labels[n1:356]\n","train_1_y=labels[356:n2]\n","test_1_y=labels[n2:695]\n","train_2_y=labels[695:n3]\n","test_2_y=labels[n3:]\n","# train_0_x.dtypes\n","# print(train_0_x)\n","X_train=np.concatenate((train_0_x,train_1_x,train_2_x),axis=0)\n","X_test = np.concatenate((test_0_x,test_1_x,test_2_x),axis=0)\n","y_train=np.concatenate((train_0_y,train_1_y,train_2_y),axis=0)\n","y_test = np.concatenate((test_0_y,test_1_y,test_2_y),axis=0)\n","\n","# print(X_train[:5])\n","# y_test"],"metadata":{"cellView":"form","id":"WeQpMgub1Czy","executionInfo":{"status":"aborted","timestamp":1701797833632,"user_tz":-330,"elapsed":52,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #####**Testing and Training The Model**\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Train a decision tree classifier (a classification model using the features and labels)\n","clf = DecisionTreeClassifier()\n","clf.fit(X_train, y_train)\n","\n","# Predict labels for test data\n","y_pred = clf.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n","# # Classify new gene sequences\n","# new_sequences =[\"ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG\" ,\"GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTA\", \"AGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAG\"]\n","\n","# new_features = []\n","# for sequence in new_sequences:\n","#     entropy_value = compute_shannon_entropy(sequence)\n","#     new_features.append([entropy_value])\n","\n","# predicted_categories = clf.predict(new_features)\n","# print(\"Predicted Categories:\", predicted_categories)\n"],"metadata":{"cellView":"form","id":"_OTSVAFl1KSi","executionInfo":{"status":"aborted","timestamp":1701797833633,"user_tz":-330,"elapsed":53,"user":{"displayName":"Pravin Raj","userId":"01804457057026731426"}}},"execution_count":null,"outputs":[]}]}